---
title: "hw06"
author: "Mielle"
date: "November 1, 2018"
output: github_document
keep_toc: true
---

```{r getting started}

library(gapminder)
library(tidyverse)
library(kableExtra)
```


# singer data
```{r INSTRUCTIONS for SINGER}
# 4. Work with the singer data
#The singer_location dataframe in the singer package contains geographical information stored in two different formats: 1. as a (dirty!) variable named city; 2. as a latitude / longitude pair (stored in latitude, longitude respectively). The function revgeocode from the ggmap library allows you to retrieve some information for a pair (vector) of longitude, latitude (warning: notice the order in which you need to pass lat and long). Read its manual page.

U#se purrr to map latitude and longitude into human readable information on the band’s origin places. Notice that revgeocode(... , output = "more") outputs a dataframe, while revgeocode(... , output = "address") returns a string: you have the option of dealing with nested dataframes.
#You will need to pay attention to two things:
#Not all of the track have a latitude and longitude: what can we do with the missing information? (filtering, …)
#Not all of the time we make a research through revgeocode() we get a result. What can we do to avoid those errors to bite us? (look at possibly() in purrr…)
#Try to check wether the place in city corresponds to the information you retrieved.

#If you still have time, you can go visual: give a look to the library leaflet and plot some information about the bands. A snippet of code is provided below.
#singer_locations %>%  
#  leaflet()  %>%   
#  addTiles() %>%  
 # addCircles(popup = ~artist_name)
```

```{r R INSTRUCTIONS FOR FUNCTIONS}
# 2. Writing functions
#Pick one:

#Write one (or more) functions that do something useful to pieces of the Gapminder or Singer data. It is logical to think about computing on the mini-data frames corresponding to the data for each specific country, location, year, band, album, … This would pair well with the prompt below about working with a nested data frame, as you could apply your function there.
#Make it something you can’t easily do with built-in functions. Make it something that’s not trivial to do with the simple dplyr verbs. The linear regression function presented here is a good starting point. You could generalize that to do quadratic regression (include a squared term) or use robust regression, using MASS::rlm() or robustbase::lmrob().


#If you plan to complete the homework where we build an R package, write a couple of experimental functions exploring some functionality that is useful to you in real life and that might form the basis of your personal package.


```

```{r multiple linear regression using lm}

# lm(y ~ x1 + x2, data = data)
lm(lifeExp ~ gdpPercap + pop , data = gapminder)

```

```{r}
function(001 ~ 002 + 003) 001, 002, 003

map2(a, b, ~ .x * .y)

```



# MODE FUNCTIONS 



```{r not anything}
levels(gapminder$continent)
countcountry <- as.vector(tabulate(gapminder$continent))
max(countcountry)
```



```{r with hard coding}
# Sanity check: works with min as well 
DF <- gapminder %>% 
  group_by(continent) %>% 
  summarise(count = length(continent)) %>%
  .[which.max(.$count),]

DF
```


```{r trying to make a function}

data_name <- gapminder
column_name <- gapminder$continent

data_name %>% 
  group_by(data_name) %>% 
  summarise(count = length(column_name)) %>%
  .[which.max(.$count),]

```


```{r function but returns something weird, issue is with summarise}

modefunction <- function(dataset, col_name){
  require("dplyr")
  dataset %>%
    group_by_(col_name) %>%
    summarise(count = length(col_name)) %>% 
  .[which.max(.$count),] -> most
  return(most)
}


modefunction(gapminder, gapminder$continent)
```
```{r set up country data as a test vector input}
countrytest<- select(gapminder, country) %>% 
  as.vector() %>% 
  group_by(country)

countrytest
```

```{r set up data as a vector input}
cont<- select(gapminder, continent) %>% 
  as.vector() %>% 
  group_by(continent)

cont
```

```{r}

# counts all categories, returns all rows with maximum count value
# tested with min

count(cont) %>%
  as.data.frame() %>% 
  filter(n == max(n))

```

```{r}

modefunction <- function(dataset){
  require("dplyr")
  count(dataset) %>%
  as.data.frame() %>% 
  filter(n == max(n)) %>% 
  select(-n) -> most
  return(most)
}


modefunction(cont)
```


```{r doesn't work}
# returns the count of the mode
count(cont) %>%
  as.data.frame() %>% 
  select(max(n)) %>% 
  max() %>% 
  as.numeric()


```

```{r not the one}

# counts each type and adds column n with count, then converts to data frame, then sort descending
count(cont) %>% 
  as.data.frame() %>%
  as.numeric(n) %>% 
  .[order(., -n),]

  #was working but now isn't, not sure what got changed  .[order(-n),]

# mtcars[order(mpg, -cyl),] 
  
# .[with(.,order(-n),)]

#[order(byDayTime$count),][1:10,]

# cont[order(-n),]

# summarise(cont, count = length(n)) %>%
#   cont[which.max(n),]

```

```{r trying to take grouping out of function but always returns first entry}

gapgroup <- gapminder %>% 
  group_by(continent)

modefunction <- function(dataset){
  require("dplyr")
    summarise(dataset, count = length(dataset)) %>%
    .[which.max(.$count),] -> most
  return(most)
}


modefunction(gapgroup)
```

```{r}
contin <- as.factor(gapminder$continent)
```




# Quadratic Regression
- function: 

- quadratic regression based on lm 
y = ax2 + bx + c,
where a is not 0
- cubic regression
- linear regression `lm()`
- select maximum r squared from the 3

```{r bivariate least-squares regression}
lm(lifeExp ~ pop + gdpPercap, data = gapminder)
```


```{r set up the data: add gdpPercap squared}

gapminder_reg <- gapminder %>% 
  mutate(gdpPercap2 = gdpPercap^2) %>% 
  mutate(gdpPercap3 = gdpPercap^3) %>% 
  mutate(pop2 = pop^2)

gapminder_reg
```

First, I'll run a least-squares linear regression to see what that looks like. Least-squares, quadratic, and cubic regression are all forms of linear regression, and I'll refer to them as least-squares, quadratic, and cubic from here on out. 

```{r least-squares regression}
lm(lifeExp ~ gdpPercap, data = gapminder_reg) %>% 
  summary()
```

This has an adjusted R-squared value of .34. Not terrible, not great. Maybe quadratic regression will have a higher R-squared?

I'm going to try modifying the least-squares regression equation built into R to see what that looks like. 

```{r quadratic regression, attempt 1}

#quadratic regression using ^2 for squared term
lm(lifeExp ~ gdpPercap + (gdpPercap^2), data = gapminder_reg) %>% 
  summary()
```

From `summary()`, I can see that the equation is still only recognizing gdpPercap as the sole explanatory variable.

Good thing I was able to go back in time and add a column to the data frame for GDP per capita squared! 

```{r quadratic regression}
lm(lifeExp ~ gdpPercap + gdpPercap2, data = gapminder_reg) %>% 
  summary()
```

As well as a column for GDP per capita cubed. 
```{r cubic regression}
lm(lifeExp ~ gdpPercap + gdpPercap3, data = gapminder_reg) %>% 
  summary()
```




```{r ideally this would work somehow? but probably wont}
lm(independent ~ dependent + dependent^2, data = data)

```


temperature conversion function from [here](https://swcarpentry.github.io/r-novice-inflammation/02-func-R/)
```{r}

funct <- function(tempf) {
  tempK <- ((tempf - 32) * (5/9)) + 273.15
  return(tempK)
}

funct(50)
```



# Option 3: Working with candy dataset

### examining the raw data
First, I need to read the .csv file into R Studio so I can take a look at it. 
```{r uploading candy survey results .csv}
candysurvey <- read.csv("candy.csv", na.strings = "")
```

```{r}
head(candysurvey)
```

```{r look at all column names}

names(candysurvey)  %>% 
  kable()

```

Ok, we have 124 columns-- clearly too many to work with. 

Based on the column titles and responses from the first few columns, it seems like the columns mostly contain either opinions about candy (or other halloween trick-or-treating offerables), degrees of separation from various celebrities/historical figures, the answers to open-ended questions, and c couple "demographic" columns-- age and trick or treating behavior. 


I'd like to see if the number of DESPAIR responses to candy types is correlated with the number of non-responses. My theory is that people will probably put JOY if they like a candy, but if they don't feel super strong dislike, they won't respond at all-- so the Non-responses probably indicate a negative feeling toward the candy. 

### wrangling 

I had some trouble visualizing the steps I would need to take, so I created the following four tables to approximate what my work flow will be. 

1) Currently, the data structure approximates this table below: 

candy | candy | question | question |  
------|-------|----------|----------|
opinion | opinion | response | response
opinion | opinion | response | response

2) First, I'll need to make a "tidy" table of the data, where each row corresponds to one entry. 

candy | opinion
------|-------
candy | JOY 
candy | DESPAIR
candy | DESPAIR 
candy | NA

3) Then, I'll have to "untidy" this table by collapsing identical candy opinions and adding a "count" field. 

candy | opinion | count |
------|---------|-------
candy | JOY | count
candy | DESPAIR | count
candy | DESPAIR | count 
candy | NA | count

4) Finally, in order to plot, I'll `spread` opinion column to give me a table I can use to make a scatter plot. 

candy | joy | despair | - |
------|-----|---------|---
candy type | count | count | count
candy type | count | count | count
I'm going to set the candy data into a tibble, and use `levels()` to check out the possible entries in the candy column. 

I used `str()` to look at the data types for each column, but the output is way too long to include in the code. All the columns are factors. Conveniently, the candy columns all begin with "X"

```{r make tibble from Candy df}
candysurvtib <- as.tibble(candysurvey) 
```

Now, I'll use `grepl()` to select only column names that contain "X"

```{r use grepl to get candy columns only}
Xcolumns <- candysurvtib[ , grepl( "X", names( candysurvtib ) ) ]

```

I'll also use `select()` to remove the one column that isn't candy. 

```{r removing column}

candyX <- select(Xcolumns, -"X.That.dress..that.went.viral.early.this.year...when.I.first.saw.it..it.was.________.")

```

I'm going to change the NA values to "NoResponse", so I can work with them later

```{r Change NA values to "NoResponse"}

# change NA to a value 
candyX[] <- lapply(candyX, as.character)
candyX[is.na(candyX)] <- "NoResponse"

```


```{r gather candy type into a column}
candytidy <- gather(candyX)

head(candytidy)
```


```{r create untidy table}
candyuntidy <- gather(candytidy) %>% 
  group_by(key, value) %>% 
  summarise(count = n()) %>%
  spread(key = "value", value = "count")

head(candyuntidy)
```


```{r Scatter plot of candy}
candyuntidy %>% 
  ggplot() +
  geom_point(aes(NoResponse, DESPAIR))
```




### exploring/analyzing 

Currently, the data structure approximates this table below: 

candy | candy | question | question |  
------|-------|----------|----------|
opinion | opinion | response | response
opinion | opinion | response | response

First, I'll need to make a "tidy" table of the data, where each row corresponds to one entry. 

candy | opinion
------|-------
candy | JOY 
candy | DESPAIR
candy | DESPAIR 
candy | NA

Then, I'll have to "untidy" this table by collapsing identical candy opinions and adding a "count" field. 

candy | opinion | count |
------|---------|-------
candy | JOY | count
candy | DESPAIR | count
candy | DESPAIR | count 
candy | NA | count

Finally, in order to plot, I'll `spread` opinion column to give me a table I can use to make a scatter plot. 

candy | joy | despair | - |
------|-----|---------|---
candy type | count | count | count
candy type | count | count | count





### more?


















# Credits

[tabulate](https://stackoverflow.com/questions/1923273/counting-the-number-of-elements-with-the-values-of-x-in-a-vector)
[summarize](https://stackoverflow.com/questions/26114525/how-to-count-how-many-values-per-level-in-a-given-factor)
[select rows with max count](https://stackoverflow.com/questions/19449615/how-to-extract-the-row-with-min-or-max-values)

[using column names in functions](https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/)
[summarise](https://www.rdocumentation.org/packages/dplyr/versions/0.7.7/topics/summarise)



















