---
title: "hw06"
author: "Mielle"
date: "November 1, 2018"
output: github_document
keep_toc: true
---

```{r getting started}

library(gapminder)
library(tidyverse)
library(kableExtra)
```


# MODE FUNCTIONS 

Unlike `mean()`, `median()`, `max()`, and `min()`, R has no built-in function to return the mode(s) of a dataset.  

I can return the mode by hard coding everything, but this doesn't help me with data down the line. 

```{r mode with hard coding}
# Sanity check: works with min as well 
modeDF <- gapminder %>% 
  group_by(continent) %>% 
  summarise(count = length(continent)) %>%
  .[which.max(.$count),]

modeDF
```


So, I wrote a function that will return the mode or modes for a grouped factor.

I'll use the gapminder dataset we've been working with in class to make this work. 

The "continent" data has a clear mode, which is Africa. This is what I used to develop my mode function. I'm going to create a new dataframe that is just a factor of continents. 

```{r set up continent data}
cont<- select(gapminder, continent) %>% 
 group_by(continent)

# check that new data frame contains all levels 
levels(cont$continent)
```

I'll create a test data set from the "country". Each country appears the same number of times, so this will be a good test to see if my mode function can handle multiple modes. 

```{r set up country data as a test vector input}

countrytest<- select(gapminder, country) %>% 
  group_by(country)

# check that new data frame contains all levels
str(countrytest$country)
```

Here is my mode function

```{r MODE FUNCTION }
#input: requires data frame with one factor
#output: data frame with factor of modes

modefunction <- function(dataset){
  require("dplyr")
  count(dataset) %>%
  as.data.frame() %>% 
  filter(n == max(n)) %>% 
  select(-n) %>% 
  droplevels() %>% 
  print.data.frame(., max = 15) -> mode
  return(mode)
}
```


And here it is, applied to the continent data. It correctly returns the mode! 

```{r}
modefunction(cont)
```

Now let's try with the country data. Looks like it works with multiple modes too! 
```{r test multimodal data}
(modefunction(countrytest))
```

Because there are so many countries, I can't just visually check to see that the output of `modefunction(countrytest)` is the same. 

 

The [assignment](http://stat545.com/Classroom/assignments/hw06/hw06.html) says not to create a function that is simple with `dplyr` verbs-- you'll notice that that's exactly what my mean function is! I had no intention of doing this using `dplyr`, but after many hours of experimenting it became pretty clear that this was by far the cleanest and most functional way that I could find to set up the mode function, especially in a way that would return multiple modes. 



# Option 3: Working with candy dataset

### examining the raw data
First, I need to read the .csv file into R Studio so I can take a look at it. 
```{r uploading candy survey results .csv}
candysurvey <- read.csv("candy.csv", na.strings = "")
```


```{r look at all column names}

names(candysurvey)  %>% 
  kable()

```

Ok, we have 124 columns-- clearly too many to work with. 

Based on the column titles and responses from the first few columns, it seems like the columns mostly contain either opinions about candy (or other halloween trick-or-treating offerables), degrees of separation from various celebrities/historical figures, the answers to open-ended questions, and c couple "demographic" columns-- age and trick or treating behavior. 


I'd like to see if the number of DESPAIR responses to candy types is correlated with the number of non-responses. My theory is that people will probably put JOY if they like a candy, but if they don't feel super strong dislike, they won't respond at all-- so the Non-responses probably indicate a negative feeling toward the candy. 

### wrangling 

I had some trouble visualizing the steps I would need to take, so I created the following four tables to approximate what my work flow will be. 

1) Currently, the data structure approximates this table below: 

candy | candy | question | question |  
------|-------|----------|----------|
opinion | opinion | response | response
opinion | opinion | response | response

2) First, I'll need to make a "tidy" table of the data, where each row corresponds to one entry. 

candy | opinion
------|-------
candy | JOY 
candy | DESPAIR
candy | DESPAIR 
candy | NA

3) Then, I'll have to "untidy" this table by collapsing identical candy opinions and adding a "count" field. 

candy | opinion | count |
------|---------|-------
candy | JOY | count
candy | DESPAIR | count
candy | NA | count

4) Finally, in order to plot, I'll `spread` opinion column to give me a table I can use to make a scatter plot. 

candy | joy | despair | - |
------|-----|---------|---
candy type | count | count | count
candy type | count | count | count
I'm going to set the candy data into a tibble, and use `levels()` to check out the possible entries in the candy column. 


I used `str()` to look at the data types for each column, but the output is way too long to include in the code. All the columns are factors. Conveniently, the candy columns all begin with "X"

Now, I'll use `grepl()` to select only column names that contain "X"

```{r use grepl to get candy columns only}
#convert to tibble
candysurvtib <- as.tibble(candysurvey)

#select desired names 
Xcolumns <- candysurvtib[ , grepl( "X", names( candysurvtib ) ) ]

```

I'll also use `select()` to remove the one column that isn't candy. 

```{r removing column}

candyX <- select(Xcolumns, -"X.That.dress..that.went.viral.early.this.year...when.I.first.saw.it..it.was.________.")

```

I'm going to change the NA values to "NoResponse", so I can work with them later

```{r Change NA values to "NoResponse"}

# change NA to a value 
candyX[] <- lapply(candyX, as.character)
candyX[is.na(candyX)] <- "NoResponse"

```


```{r gather candy type into a column}
candytidy <- gather(candyX)

head(candytidy) %>% 
  kable()
```


```{r create untidy table}
candyuntidycount <- gather(candytidy) %>% 
  group_by(key, value) %>% 
  summarise(count = n()) %>%
  spread(key = "value", value = "count")


head(candyuntidycount) %>% 
  kable()
```

For my final wrangle, I'm going to convert joy, despair, and noresponse into proportions by dividing them out of 5,658 (the total)

```{r}
candyuntidy<- candyuntidycount %>% 
  mutate(DESPAIR = DESPAIR / 5658) %>% 
  mutate(JOY = JOY / 5658) %>% 
  mutate(NoResponse = NoResponse / 5658)

head(candyuntidy) %>% 
  kable()
```


### exploring/analyzing 

I'm going to make a scatter plot of Despair responses against No Response to see if they are correlated. 

```{r scatter plot: no response vs. despair}

# scatter plot: noresponse vs. despair
ggplot(candyuntidy, aes(NoResponse, DESPAIR)) +
   geom_smooth(color = "dark grey") +
  geom_point(color = "darkcyan") + 
  ggtitle("Candy opinions: Does lack of responses predict despair responses?") +
  xlab("No response") +
  ylab("Despair") +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, color = "grey50")) +
  theme(axis.text.y = element_text(color = "grey50")) +
  theme(panel.grid.major.x= element_blank(),
        panel.grid.minor.x= element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.border = element_blank(),
        axis.ticks = element_blank()) +
  theme(text=element_text(size = 10, family = "Arial", color = "grey30"))
```

It's a bit messy, but there does seem to be some positive correlation between no response and despair responses. 

I'll check joy responses as well. 


```{r scatter plot: no response vs. joy}

#scatter plot, no response vs. joy 
ggplot(candyuntidy, aes(NoResponse, JOY)) +
   geom_smooth(color = "dark grey") +
  geom_point(color = "tomato3") + 
  ggtitle("Candy opinions: Does lack of responses predict joy responses?") +
  xlab("No response") +
  ylab("Joy") +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, color = "grey50")) +
  theme(axis.text.y = element_text(color = "grey50")) +
  theme(panel.grid.major.x= element_blank(),
        panel.grid.minor.x= element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.border = element_blank(),
        axis.ticks = element_blank()) +
  theme(text=element_text(size = 10, family = "Arial", color = "grey30"))
```

Unsurprisingly, joy appears to be slightly negatively correlated with no responses. 


Overall, there does appear to be a slight correlation between lack of responses and despair responses like I initially hypothesized. 



# Credits

I didn't end up applying all these resources to the code you see here, but used all of them somewhere in the development process. 

[tabulate](https://stackoverflow.com/questions/1923273/counting-the-number-of-elements-with-the-values-of-x-in-a-vector)

[select rows with max count](https://stackoverflow.com/questions/19449615/how-to-extract-the-row-with-min-or-max-values)

[using column names in functions](https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/)

[summarise](https://www.rdocumentation.org/packages/dplyr/versions/0.7.7/topics/summarise)

[print.data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/print.dataframe.html)

[candy data](https://github.com/jennybc/candy/blob/master/data-raw/CANDY-HIERARCHY-2015%20SURVEY-Responses.csv)

[subsetting based on part of column name](https://stackoverflow.com/questions/18587334/subset-data-to-contain-only-columns-whose-names-match-a-condition)

[dplyr refresher](http://genomicsclass.github.io/book/pages/dplyr_tutorial.html)

[R colors](http://sape.inf.usi.ch/quick-reference/ggplot2/colour)


















